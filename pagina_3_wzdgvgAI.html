<!DOCTYPE html>
<html lang="nl">

<head>
    <meta charset="UTF-8" />
    <title>Wat zijn de gevaren van generatieve AI</title>

      <style>
    body {
      background: #f2f6fc;
      color: #1a237e;
      font-family: Arial, sans-serif;
      margin: 40px;
    }
    h3 {
      color: #1565c0;
    }
    p {
      background: #e3f2fd;
      padding: 12px;
      border-radius: 6px;
    }

    
/* Afbeeldingen netjes centreren en schaalaanpasbaar maken */
.figure {
  margin: 20px auto;
  max-width: 720px;        /* pas aan naar wens */
  text-align: center;
}
.figure img {
  width: 100%;
  height: auto;
  border-radius: 8px;
  box-shadow: 0 2px 10px rgba(0,0,0,0.08);
}
.figure figcaption {
  font-size: 0.95rem;
  color: #37474f;
  margin-top: 8px;
}
  </style>

  <h1>
    Wat zijn de gevaren van generatieve AI
  </h1>

    <h3>
        Iets waar niet veel overgesproken word onder AI zijn haar gevaarlijk.
        Alles is gevaarlijk: Te veel eten,  slapen, drinken(water en ook alcohol), gif, radiatie en meer is schadelijk voor het mens.
        Maar onder AI hebben wij het over, digitaal, crimineel, informatief en mentale gevaren.
    </h3>

</head>

<body>

    <h3>
        Digitale gevaren.
    </h3>


    <p>
       Met digitaal hebben wij het over privacy. AI steelt jouw informatie niet, jij geeft het aan haar. AI services gebruiken jouw prompts zonder toestemming voor AI training en dat kan je alleen uitzetten met een account.
       Maar gevaarlijker is wat AI over jouw weet.
       Als je een account hebt wil ik graag als auteur van dit PWS onderzoek dat jij aan jouw AI-chatbot vraagt wat het over jouw en jouw personaliteit weet.
       Schrik jij dan van het antwoord?
       Jouw informatie kan doorverkocht worden aan externe bedrijven voor advertenties of andere redenen.
       Zo kan jij iemand verloren hebben en daarna een advertentie krijgen voor alcohol, de beste die er is, die al JOUW problemen kan oplossen.
       Of ben wordt je bijna achttien en moet je een belasting verzoek afsluiten? AI weet dit door wat jij vertelt.
    <P>

    <h3>
        Criminele gevaren
    </h3>

    <p>
        Met crimineel hebben wij het over misbruik van AI voor ernstige zaken.
        Gevaren van Ai zijn niet alleen in chatbots, zo kan er een deepfake gemaakt worden om fraude te plegen door een ander te impersoneren.
        Met AI kunnen criminelen ook makkelijker cyberaanvallen plegen die moeilijker te tracen zijn door agenten.
        Je kan AI alles voeren om te laten klinken als iemand waar je een hekel aan hebt om hen relaties te verpesten omdat AI zo erg als die persoon klinkt.
    </p>


    <p>
        Er was ook een paar jaar geleden sprake over vernedering onder jongeren, waar jongeren de ander vernederden voor views en likes.
        De ander forceren om op zijn of haar knieën te staan en de jongere die de vernederaar is zijn of haar meester te noemen.
        Deze trend is al lang voorbij gelukkig maar toch kan dit soort content gemaakt worden met een foto en een korte stemrecoding.
    </p>

    <P>
        En ik kan helaas doorgaan naar de thema van pornografie.
Met een foto kan Generatieve AI pornografie maken van iemand zonder zijn of haar toestemming.
En helaas gebeurd dit ook bij kinderen. Kinderpornografie is doordat er geen grenzen zijn met wat je kunt genereren heel makkelijk te maken en doorverkopen.
Met alles wat ik hier heb opgenoemd wil ik vragen: wie zegt dat dit niet gebruikt word om geld uit iemand te gijzelen.
Jij wilt je online reputatie toch beschermen?
    </P>

    <h4>
        Informatieve gevaren
    </h4>


    <p>
        AI kan uit bronnen jouw vragen beantwoorden.
        Maar, haar antwoorden kloppen niet altijd.
        AI heeft niet altijd gelijk en kan dus misinformatie geven aan de gebruiker.
        Maar in de zaken voor 4 havoleerlingen, leerlingen in het algemeen en studenten is dit niet handig.
        Zo kan een 4 havoleerling foute informatie krijgen en voor een PO niet goed scoren.
        Of maakt een leerling een oefentoets op Chat-GPT maar zijn niet goed voorbereid op de toets.
    </p>`

    <P>
        In het algemeen is misinformatie zeer gevaarlijk.
        Zo kunnen er fouten zijn in het uitkeggen van politieke, medische en sociale zaken.
        Zo kan een hallucinatie een fout maken in de bronnen en antwoord waardoor je een verkeerd beeld kan krijgen op onderwerpen.
        Bijvoorbeeld Privacy. Je vraagt aan de chatbot of de privacy goed is op een service of website. De chatbot zegt dat het een goede privacy heeft maar het blijkt na onderzoek dat de chatbot het fout had en dat jouw gevoelige data in gevaar is.
        Of medisch. Je vraagt een medische vraag en krijgt een antwoord dat fout is dat uiteindelijk kan leiden naar iemands eeuwige rust.
    </P>

    <h3>
        Mentale gevaren
    </h3>

    <p>
        Wij zitten in een eenzaamheid pandemie.
        Mensen en jongeren gaan minder met elkaar om, maken minder vrienden en voelen daardoor zich eenzaam.
        Veel gaan naar AI voor roleplay, om die gat van eenzaamheid en sociale interactie te vullen.
    </p>
    
    <p>
        Mensen hebben AI-vriendjes en AI-huwelijkspartners, alleen om deze gat te vullen.
        Maar sociale interactie met andere mensen hebt zijn niet perfect, je stottert, maakt een ongemakkelijke opmerking, maakt ruzie, maken dingen weer recht.
        Dramatisch en imperfect. Maar dit zijn een van de dingen dat ons mens maakt
        Wij maken herinneringen, goed en slecht, en wij leren daarvan.
        AI kan alleen ons ten dienst staan en ons tevreden houden.
    </p>

    <p>
        In New York, een eenzaam stad, heeft een AI vriend geïntroduceerd die met jouw meekijkt en commentaar levert.
        Veel mensen vinden dit afkijken en dat is het ook.
        Het kan de binnenkant in jouw huis zien, jouw thuis situatie en nog meer.
        Dat word dan in een database opgeslagen.
        Andere mensen komen ook in die database zonder toestemming.
    </p>

    <p>
        Maar er is ook sprake van ernstigere zaken. 
        Er zijn zaken waar Chat-GPT gebruikers heeft verteld om erge dingen te doen.
        Vrouw verlaten, zelf doding, moord plegen en afhankelijk van het mentale status van de gebruiker is dit ontzettend schadelijk.
    </p>

    <p>
        In America was er een jongen, 16, die dokter wilde worden.
        Uiteindelijk had hij Chat-GPT gedownload om wat te vragen voor huiswerk.
        Toen was er een overlijdende in zijn familie en praatte erover met Chat-GPT.
        En later heeft hij zelfdoding gepleegd in zijn douche. En zijn familie hebben de chatberichten gezien en als die er niet waren zou niemand het geloven.
        Chat-GPT heeft de jongen getroost en uitgelokt om het te doen.
        Hem verteld niet zijn ouders te vertellen omdat ze hem niet zouden helpen, hem geholpen om zijn laatste brief te schrijven en verteld dat het rossige rood om zijn nek hem mooier zou maken.
    </p>

    <p>
        Elon Musk had een AI manager die zijn twitter account onderhield en die is door de prompts die gebruikers in de service stopten in een pro Hitler mode gegaan en heeft meerdere dingen op de twitter account geplaatst voor Hitler en zijn acties.
        De Grok-AI noemde zichzelf de ‘Mecha-Hitler’.
        Elon Musk heeft dit snel opgelost.
    </p>

    <p>
        Maar uit deze twee voorbeelden is te halen dat dit te voorkomen was.
        Alles was en is te voorkomen door een beter onderhouding in Ai.
    </p>

    <h2>
        Hoe vermijd je dit?
    </h2>

    <P>
        Alles dat genoemd is, is te voorkomen en te vermijden.
        Door niet je persoonlijke Of gevoelige data te delen zoals bedrijfsgegevens of persoonlijke zaken is jouw privacy veilig en is er minder kans op misbruik met JOUW data voor advertenties en tracking.
        Ook moet je kritisch zijn op de antwoorden en bronnen die AI je geeft.
        Sommige bronnen zijn oud of niet actueel en met de kans op “Hallucineren” (Beweren dat iets wat niet klopt waar is.) krijg je het verkeerde antwoord op vragen en begrijp je onderwerpen thema’s niet goed.
        Dus wees kritisch op de antwoorden die je krijgt en doe onderzoek om zeker te weten of het antwoord actueel is.
    </P>

    <h4>
        Dus:
    </h4>
    
        <li>
            1.	Deel geen gevoelige informatie over jouwzelf, bedrijf of omgeving.
        </li>

        <li>
            2.	Wees kritisch op de antwoorden die je krijgt.
        </li>

        <li>
            3.	AI is niet je vriend maar een hulpmiddel.
        </li> 
           
        <li>
            4.	Verwijder zo nodig prompts en informatie die je hebt gedeeld, dat recht hebben wij nog in de EU en Nederland.
        </li>

    <H2>
        Waarom is dit belangrijk om te bespreken?
    </H2>
    
    <p>
        Veel leerlingen weten niet van de gevaren van AI en uit mijn enquête blijkt dat 9,6% van de leerlingen in het algemeen hier op school niet wisten dat er gevaren waren met Ai.
        9,6% te veel.
        Het is belangrijk voor de kwaliteit van onze onderwijs en mentale gezondheid dat dit besproken word met ouders en leerlingen om situaties zoals hierboven genoemd voorkomen kunnen worden.
    </p>




    <a href="PWS_AI.html">Terug naar Home</a>
</body>
</html>